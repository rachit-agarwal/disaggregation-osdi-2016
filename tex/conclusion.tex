\section{Conclusion}
In this paper, we take a first step towards understanding what network support is required for resource disaggregation. Using a workload-driven approach, we evaluate: what end-to-end latency and bandwidth must the network in a \dis provide to avoid degrading application performance? We find that -- in the absence of queueing delay and other transport-layer protocol overheads -- a bandwidth of $40$Gbps and $3-5\mu$s end-to-end latencies will suffice. We examine the feasibility of achieving these targets and conclude they are within reach assuming the adoption of recent/emerging technologies such as RDMA and NIC integration. We next evaluate whether existing network and transport designs are compatible with the performance targets we identify. We find that even state-of-the-art transport protocols such as pFabric introduce non-trivial performance overheads but the adoption of faster 100Gbps links be compensate for these overheads. 

Taken together, we are cautiously optimistic about the ability to meet the needs of \dis with existing network designs and components but also identify several avenues for future improvements and research. We believe that quantified, workload-driven studies such as that presented in this paper can serve to inform ongoing and future efforts to build \dis systems. 

\cut{ 

that a network must provide to avoid degrading 
performance 
requirements from the network to avoid degrading application-level performance? (ii) how and why will traffic characteristics change due to disaggregation? (iii) can existing network designs meet the network requirements?

We find that a network with end-to-end latency for $5$--$10\mu$s and $40$Gbps access link capacity may be sufficient to ensure little or no degradation in application-level performance. Many of the tenets that have guided datacenter design so far may not hold in the context of disaggregated datacenters. Finally, we find that state-of-the-art protocols may be adequate for disaggregation.
}