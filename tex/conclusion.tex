\section{Conclusion}
In this paper, we take a first step towards understanding application performance in future disaggregated datacenters. Using a workload-driven approach, we find that an end-to-end network latency of 3-5 $\mu$s and link bandwidth of $100$Gbps will result in only minor degradations in application performance.

Taken together, we are cautiously optimistic about the ability to meet the needs of \dis with existing network designs and components but also identify several avenues for future improvements and research. We believe that quantified, workload-driven studies such as that presented in this paper can serve to inform ongoing and future efforts to build \dis systems. 

\cut{ 

that a network must provide to avoid degrading 
performance 
requirements from the network to avoid degrading application-level performance? (ii) how and why will traffic characteristics change due to disaggregation? (iii) can existing network designs meet the network requirements?

We find that a network with end-to-end latency for $5$--$10\mu$s and $40$Gbps access link capacity may be sufficient to ensure little or no degradation in application-level performance. Many of the tenets that have guided datacenter design so far may not hold in the context of disaggregated datacenters. Finally, we find that state-of-the-art protocols may be adequate for disaggregation.
}